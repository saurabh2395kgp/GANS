{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import os\nimport pickle\nimport random\nimport time\nimport PIL\nimport numpy as np\nimport pandas as pd\nimport tensorflow as tf\nfrom PIL import Image\nfrom keras import Input, Model\nfrom keras import backend as K\nfrom keras.callbacks import TensorBoard\nfrom keras.layers import Dense, LeakyReLU, BatchNormalization, ReLU, Reshape, UpSampling2D, Conv2D, Activation, concatenate, Flatten, Lambda, Concatenate\nfrom keras.optimizers import Adam\nfrom keras_preprocessing.image import ImageDataGenerator\nfrom matplotlib import pyplot as plt","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Start by creating a fully connected layer with 256 nodes and LeakyReLU as the\nactivation function:"},{"metadata":{"trusted":true},"cell_type":"code","source":"input_layer = Input(shape=(1024,))\nx = Dense(256)(input_layer)\nmean_logsigma = LeakyReLU(alpha=0.2)(x)\n#The input shape is (batch_size, 1024), and the output shape is (batch_size,256).","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Next, split mean_logsigma into mean and log_sigma tensors:"},{"metadata":{"trusted":true},"cell_type":"code","source":"mean = x[:, :128]\nlog_sigma = x[:, 128:]\n#This operation creates two tensors of dimensions (batch_size, 128) and (batch_size, 128).","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Next, calculate the text conditioning variable using the following code."},{"metadata":{"trusted":true},"cell_type":"code","source":"stddev = K.exp(log_sigma)\nepsilon = K.random_normal(shape=K.constant((mean.shape[1], ), dtype='int32'))\nc = stddev * epsilon + mean","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def generate_c(x):\n mean = x[:, :128]\n log_sigma = x[:, 128:]\n stddev = K.exp(log_sigma)\n epsilon = K.random_normal(shape=K.constant((mean.shape[1], ), dtype='int32'))\n c = stddev * epsilon + mean\n return c","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def build_ca_model():\n input_layer = Input(shape=(1024,))\n x = Dense(256)(input_layer)\n mean_logsigma = LeakyReLU(alpha=0.2)(x)\n c = Lambda(generate_c)(mean_logsigma)\n return Model(inputs=[input_layer], outputs=[c])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def build_embedding_compressor_model():\n    \"\"\"\n    Build embedding compressor model\n    \"\"\"\n    input_layer = Input(shape=(1024,))\n    x = Dense(128)(input_layer)\n    x = ReLU()(x)\n\n    model = Model(inputs=[input_layer], outputs=[x])\n    return model","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The Generator Network:-"},{"metadata":{"trusted":true},"cell_type":"code","source":"def build_stage1_generator():\n \"\"\"\n Builds a generator model\n \"\"\"\n input_layer = Input(shape=(1024,))\n x = Dense(256)(input_layer)\n mean_logsigma = LeakyReLU(alpha=0.2)(x)\n c = Lambda(generate_c)(mean_logsigma)\n input_layer2 = Input(shape=(100,))\n gen_input = Concatenate(axis=1)([c, input_layer2])\n x = Dense(128 * 8 * 4 * 4, use_bias=False)(gen_input)\n x = ReLU()(x)\n x = Reshape((4, 4, 128 * 8), input_shape=(128 * 8 * 4 * 4,))(x)\n x = UpSampling2D(size=(2, 2))(x)\n x = Conv2D(512, kernel_size=3, padding=\"same\", strides=1, use_bias=False)(x)\n x = BatchNormalization()(x)\n x = ReLU()(x)\n x = UpSampling2D(size=(2, 2))(x)\n x = Conv2D(256, kernel_size=3, padding=\"same\", strides=1, use_bias=False)(x)\n x = BatchNormalization()(x)\n x = ReLU()(x)\n x = UpSampling2D(size=(2, 2))(x)\n x = Conv2D(128, kernel_size=3, padding=\"same\", strides=1, use_bias=False)(x)\n x = BatchNormalization()(x)\n x = ReLU()(x)\n x = UpSampling2D(size=(2, 2))(x)\n x = Conv2D(64, kernel_size=3, padding=\"same\", strides=1, use_bias=False)(x)\n x = BatchNormalization()(x)\n x = ReLU()(x)\n x = Conv2D(3, kernel_size=3, padding=\"same\", strides=1, use_bias=False)(x)\n x = Activation(activation='tanh')(x)\n stage1_gen = Model(inputs=[input_layer, input_layer2], outputs=[x, mean_logsigma])\n return stage1_gen","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**BUILD STAGE1 DISCRIMINATOR**"},{"metadata":{"trusted":true},"cell_type":"code","source":"def build_stage1_discriminator():\n input_layer = Input(shape=(64, 64, 3))\n x = Conv2D(64, (4, 4),padding='same', strides=2,input_shape=(64, 64, 3), use_bias=False)(input_layer)\n x = LeakyReLU(alpha=0.2)(x)\n x = Conv2D(128, (4, 4), padding='same', strides=2, use_bias=False)(x)\n x = BatchNormalization()(x)\n x = LeakyReLU(alpha=0.2)(x)\n x = Conv2D(256, (4, 4), padding='same', strides=2, use_bias=False)(x)\n x = BatchNormalization()(x)\n x = LeakyReLU(alpha=0.2)(x)\n x = Conv2D(512, (4, 4), padding='same', strides=2, use_bias=False)(x)\n x = BatchNormalization()(x)\n x = LeakyReLU(alpha=0.2)(x)\n input_layer2 = Input(shape=(4, 4, 128))\n merged_input = concatenate([x, input_layer2])\n x2 = Conv2D(64 * 8, kernel_size=1,\n padding=\"same\", strides=1)(merged_input)\n x2 = BatchNormalization()(x2)\n x2 = LeakyReLU(alpha=0.2)(x2)\n x2 = Flatten()(x2)\n x2 = Dense(1)(x2)\n x2 = Activation('sigmoid')(x2)\n stage1_dis = Model(inputs=[input_layer, input_layer2], outputs=[x2])\n return stage1_dis","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#gen_model=build_stage1_generator()\n#dis_model=build_stage1_discriminator()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"##model = Model(inputs=[input_layer, input_layer2, input_layer3], outputs=[valid","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 4. Finally, create the adversarial model, taking three inputs and returning two\n# outputs.\n# model = Model(inputs=[input_layer, input_layer2, input_layer3], outputs=[valid\n# return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def build_adversarial_model(gen_model, dis_model):\n input_layer = Input(shape=(1024,))\n input_layer2 = Input(shape=(100,))\n input_layer3 = Input(shape=(4, 4, 128))\n # Get output of the generator model\n x, mean_logsigma = gen_model([input_layer, input_layer2])\n # Make discriminator trainable false\n dis_model.trainable = False\n # Get output of the discriminator models\n valid = dis_model([x, input_layer3])\n model = Model(inputs=[input_layer, input_layer2, input_layer3], outputs=[valid,mean_logsigma])\n return model","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Stage 2 begins"},{"metadata":{},"cell_type":"markdown","source":"Generator is made up of 3 parts:-"},{"metadata":{},"cell_type":"markdown","source":" **Stage 2 GENERATOR**"},{"metadata":{"trusted":true},"cell_type":"code","source":"def build_stage2_generator():\n \"\"\"\n Create a generator network for Stage-II StackGAN\n \"\"\"\n # 1. CA Augementation Network\n input_layer = Input(shape=(1024,))\n input_lr_images = Input(shape=(64, 64, 3))\n ca = Dense(256)(input_layer)\n mean_logsigma = LeakyReLU(alpha=0.2)(ca)\n c = Lambda(generate_c)(mean_logsigma)\n # 2. Image Encoder\n x = ZeroPadding2D(padding=(1, 1))(input_lr_images)\n x = Conv2D(128, kernel_size=(3, 3), strides=1, use_bias=False)(x)\n x = ReLU()(x)\n x = ZeroPadding2D(padding=(1, 1))(x)\n x = Conv2D(256, kernel_size=(4, 4), strides=2, use_bias=False)(x)\n x = BatchNormalization()(x)\n x = ReLU()(x)\n x = ZeroPadding2D(padding=(1, 1))(x)\n x = Conv2D(512, kernel_size=(4, 4), strides=2, use_bias=False)(x)\n x = BatchNormalization()(x)\n x = ReLU()(x)\n # Concatenation block\n c_code = Lambda(joint_block)([c, x])\n # 3. Residual Blocks\n x = ZeroPadding2D(padding=(1, 1))(c_code)\n x = Conv2D(512, kernel_size=(3, 3), strides=1, use_bias=False)(x)\n x = BatchNormalization()(x)\n x = ReLU()(x)\n x = residual_block(x)\n x = residual_block(x)\n x = residual_block(x)\n x = residual_block(x)\n # 4. Upsampling blocks\n x = UpSampling2D(size=(2, 2))(x)\n x = Conv2D(512, kernel_size=3, padding=\"same\", strides=1, use_bias=False)(x)\n x = BatchNormalization()(x)\n x = ReLU()(x)\n x = UpSampling2D(size=(2, 2))(x)\n x = Conv2D(256, kernel_size=3, padding=\"same\", strides=1, use_bias=False)(x)\n x = BatchNormalization()(x)\n x = ReLU()(x)\n x = UpSampling2D(size=(2, 2))(x)\n x = Conv2D(128, kernel_size=3, padding=\"same\", strides=1, use_bias=False)(x)\n x = BatchNormalization()(x)\n x = ReLU()(x)\n x = UpSampling2D(size=(2, 2))(x)\n x = Conv2D(64, kernel_size=3, padding=\"same\", strides=1, use_bias=False)(x)\n x = BatchNormalization()(x)\n x = ReLU()(x)\n x = Conv2D(3, kernel_size=3, padding=\"same\", strides=1, use_bias=False)(x)\n x = Activation('tanh')(x)\n model = Model(inputs=[input_layer, input_lr_images], outputs=[x, mean_logsigma])\n return model","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**THE DISCRIMINATOR NETWORK**"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Start by creating an input layer as follows:\ninput_layer = Input(shape=(256, 256, 3))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def build_stage2_discriminator():\n input_layer = Input(shape=(256, 256, 3))\n x = Conv2D(64, (4, 4), padding='same', strides=2, input_shape=(256, 256, 3), use_bias=False)(input_layer)\n x = LeakyReLU(alpha=0.2)(x)\n x = Conv2D(128, (4, 4), padding='same', strides=2, use_bias=False)(x)\n x = BatchNormalization()(x)\n x = LeakyReLU(alpha=0.2)(x)\n x = Conv2D(256, (4, 4), padding='same', strides=2, use_bias=False)(x)\n x = BatchNormalization()(x)\n x = LeakyReLU(alpha=0.2)(x)\n x = Conv2D(512, (4, 4), padding='same', strides=2, use_bias=False)(x)\n x = BatchNormalization()(x)\n x = LeakyReLU(alpha=0.2)(x)\n x = Conv2D(1024, (4, 4), padding='same', strides=2, use_bias=False)(x)\n x = BatchNormalization()(x)\n x = LeakyReLU(alpha=0.2)(x)\n x = Conv2D(2048, (4, 4), padding='same', strides=2, use_bias=False)(x)\n x = BatchNormalization()(x)\n x = LeakyReLU(alpha=0.2)(x)\n x = Conv2D(1024, (1, 1), padding='same', strides=1, use_bias=False)(x)\n x = BatchNormalization()(x)\n x = LeakyReLU(alpha=0.2)(x)\n x = Conv2D(512, (1, 1), padding='same', strides=1, use_bias=False)(x)\n x = BatchNormalization()(x)\n x2 = Conv2D(128, (1, 1), padding='same', strides=1, use_bias=False)(x)\n x2 = BatchNormalization()(x2)\n x2 = LeakyReLU(alpha=0.2)(x2)\n x2 = Conv2D(128, (3, 3), padding='same', strides=1, use_bias=False)(x2)\n x2 = BatchNormalization()(x2)\n x2 = LeakyReLU(alpha=0.2)(x2)\n x2 = Conv2D(512, (3, 3), padding='same', strides=1, use_bias=False)(x2)\n x2 = BatchNormalization()(x2)\n added_x = add([x, x2])\n added_x = LeakyReLU(alpha=0.2)(added_x)\n input_layer2 = Input(shape=(4, 4, 128))\n # Concatenation block\n merged_input = concatenate([added_x, input_layer2])\n x3 = Conv2D(64 * 8, kernel_size=1, padding=\"same\", strides=1)(merged_input)\n x3 = BatchNormalization()(x3)\n x3 = LeakyReLU(alpha=0.2)(x3)\n x3 = Flatten()(x3)\n x3 = Dense(1)(x3)\n x3 = Activation('sigmoid')(x3)\n stage2_dis = Model(inputs=[input_layer, input_layer2], outputs=[x3])\n return stage2_dis","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Training the Stage-I StackGAN**"},{"metadata":{"trusted":true},"cell_type":"code","source":"data_dir = \"../input/data birds/data birds/embed\"\ntrain_dir = data_dir + \"/train\"\ntest_dir = data_dir + \"/test\"\nimage_size = 64\nbatch_size = 64\nz_dim = 100\nstage1_generator_lr = 0.0002\nstage1_discriminator_lr = 0.0002\nstage1_lr_decay_step = 600\nepochs = 100\ncondition_dim = 128\nembeddings_file_path_train = train_dir + \"/char-CNN-RNN-embeddings.pickle\"\nembeddings_file_path_test = test_dir + \"/char-CNN-RNN-embeddings.pickle\"\nfilenames_file_path_train = train_dir + \"/filenames.pickle\"\nfilenames_file_path_test = test_dir + \"/filenames.pickle\"\nclass_info_file_path_train = train_dir + \"/class_info.pickle\"\nclass_info_file_path_test = test_dir + \"/class_info.pickle\"\ncub_dataset_dir = \"../input/data birds/data birds/data\"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"LOADING DATASET"},{"metadata":{"trusted":true},"cell_type":"code","source":"def load_class_ids(class_info_file_path):\n  \"\"\"\n  Load class ids from class_info.pickle file\n  \"\"\"\n  with open(class_info_file_path, 'rb') as f:\n      class_ids = pickle.load(f, encoding='latin1')\n  return class_ids","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def load_filenames(filenames_file_path):\n  \"\"\"\n  Load filenames.pickle file and return a list of all file names\n  \"\"\"\n  with open(filenames_file_path, 'rb') as f:\n      filenames = pickle.load(f, encoding='latin1')\n      return filenames","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def load_bounding_boxes(dataset_dir):\n  \"\"\"\n  Load bounding boxes and return a dictionary of file names and corresponding bounding boxes\n  \"\"\"\n  # Paths\n  bounding_boxes_path = os.path.join(dataset_dir, 'bounding_boxes.txt')\n  file_paths_path = os.path.join(dataset_dir, 'images.txt')\n  # Read bounding_boxes.txt and images.txt file\n  df_bounding_boxes = pd.read_csv(bounding_boxes_path,\n  delim_whitespace=True, header=None).astype(int)\n  df_file_names = pd.read_csv(file_paths_path, delim_whitespace=True, header=None)\n  # Create a list of file names\n  file_names = df_file_names[1].tolist()\n  # Create a dictionary of file_names and bounding boxes\n  filename_boundingbox_dict = {img_file[:-4]: [] for img_file in file_names[:2]}\n  # Assign a bounding box to the corresponding image\n  for i in range(0, len(file_names)):\n      # Get the bounding box\n      bounding_box = df_bounding_boxes.iloc[i][1:].tolist()\n      key = file_names[i][:-4]\n      filename_boundingbox_dict[key] = bounding_box\n  return filename_boundingbox_dict","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def load_embeddings(embeddings_file_path):\n    \"\"\"\n    Load embeddings\n    \"\"\"\n    with open(embeddings_file_path, 'rb') as f:\n        embeddings = pickle.load(f, encoding='latin1')\n        embeddings = np.array(embeddings)\n        print('embeddings: ', embeddings.shape)\n    return embeddings","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_img(img_path, bbox, image_size):\n \"\"\"\n Load and resize image\n \"\"\"\n img = Image.open(img_path).convert('RGB')\n width, height = img.size\n if bbox is not None:\n     R = int(np.maximum(bbox[2], bbox[3]) * 0.75)\n     center_x = int((2 * bbox[0] + bbox[2]) / 2)\n     center_y = int((2 * bbox[1] + bbox[3]) / 2)\n     y1 = np.maximum(0, center_y - R)\n     y2 = np.minimum(height, center_y + R)\n     x1 = np.maximum(0, center_x - R)\n     x2 = np.minimum(width, center_x + R)\n     img = img.crop([x1, y1, x2, y2])\n img = img.resize(image_size, PIL.Image.BILINEAR)\n return img","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def load_dataset(filenames_file_path, class_info_file_path, cub_dataset_dir, embeddings_file_path,image_size):\n filenames = load_filenames(filenames_file_path)\n class_ids = load_class_ids(class_info_file_path)\n bounding_boxes = load_bounding_boxes(cub_dataset_dir)\n all_embeddings = load_embeddings(embeddings_file_path)\n X, y, embeddings = [], [], []\n # TODO: Change filenames indexing\n for index, filename in enumerate(filenames[:500]):\n     #print(class_ids[index], filenames[index])\n     bounding_box = bounding_boxes[filename]\n     try:\n         # Load images\n         img_name = '{}/images/{}.jpg'.format(cub_dataset_dir, filename)\n         img = get_img(img_name, bounding_box, image_size)\n         all_embeddings1 = all_embeddings[index, :, :]\n         embedding_ix = random.randint(0, all_embeddings1.shape[0] - 1)\n         embedding = all_embeddings1[embedding_ix, :]\n         X.append(np.array(img))\n         y.append(class_ids[index])\n         embeddings.append(embedding)\n     except Exception as e:\n        print(e)\n X = np.array(X)\n y = np.array(y)\n embeddings = np.array(embeddings)\n return X, y, embeddings","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, y_train, embeddings_train = load_dataset(filenames_file_path=filenames_file_path_train,class_info_file_path=class_info_file_path_train,cub_dataset_dir=cub_dataset_dir,embeddings_file_path=embeddings_file_path_train,image_size=(64, 64))\nX_test, y_test, embeddings_test = load_dataset(filenames_file_path=filenames_file_path_test,class_info_file_path=class_info_file_path_test,cub_dataset_dir=cub_dataset_dir,embeddings_file_path=embeddings_file_path_test,image_size=(64, 64))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dis_optimizer = Adam(lr=stage1_discriminator_lr, beta_1=0.5, beta_2=0.999)\ngen_optimizer = Adam(lr=stage1_generator_lr, beta_1=0.5, beta_2=0.999)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def KL_loss(y_true, y_pred):\n    mean = y_pred[:, :128]\n    logsigma = y_pred[:, :128]\n    loss = -logsigma + .5 * (-1 + K.exp(2. * logsigma) + K.square(mean))\n    loss = K.mean(loss)\n    return loss","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ca_model = build_ca_model()\nca_model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\")\n\nstage1_dis = build_stage1_discriminator()\nstage1_dis.compile(loss='binary_crossentropy', optimizer=dis_optimizer)\n\nstage1_gen = build_stage1_generator()\nstage1_gen.compile(loss=\"mse\", optimizer=gen_optimizer)\n\nembedding_compressor_model = build_embedding_compressor_model()\nembedding_compressor_model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\")\n\nadversarial_model = build_adversarial_model(gen_model=stage1_gen, dis_model=stage1_dis)\nadversarial_model.compile(loss=['binary_crossentropy', KL_loss], loss_weights=[1,2.0],\noptimizer=gen_optimizer, metrics=None)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tensorboard = TensorBoard(log_dir=\"logs/\".format(time.time()))\ntensorboard.set_model(stage1_gen)\ntensorboard.set_model(stage1_dis)\ntensorboard.set_model(ca_model)\ntensorboard.set_model(embedding_compressor_model)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"real_labels = np.ones((batch_size, 1), dtype=float) * 0.9\nfake_labels = np.zeros((batch_size, 1), dtype=float) * 0.1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def save_rgb_img(img, path):\n    \"\"\"\n    Save an rgb image\n    \"\"\"\n    fig = plt.figure()\n    ax = fig.add_subplot(1, 1, 1)\n    ax.imshow(img)\n    ax.axis(\"off\")\n    ax.set_title(\"Image\")\n    plt.close()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def write_log(callback, name, loss, batch_no):\n    \"\"\"\n    Write training summary to TensorBoard\n    \"\"\"\n    summary = tf.Summary()\n    summary_value = summary.value.add()\n    summary_value.simple_value = loss\n    summary_value.tag = name\n    callback.writer.add_summary(summary, batch_no)\n    callback.writer.flush()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for epoch in range(epochs):\n        print(\"========================================\")\n        print(\"Epoch is:\", epoch)\n        print(\"Number of batches\", int(X_train.shape[0] / batch_size))\n\n        gen_losses = []\n        dis_losses = []\n\n        # Load data and train model\n        number_of_batches = int(X_train.shape[0] / batch_size)\n        for index in range(number_of_batches):\n            print(\"Batch:{}\".format(index+1))\n            \n            \"\"\"\n            Train the discriminator network\n            \"\"\"\n            # Sample a batch of data\n            z_noise = np.random.normal(0, 1, size=(batch_size, z_dim))\n            image_batch = X_train[index * batch_size:(index + 1) * batch_size]\n            embedding_batch = embeddings_train[index * batch_size:(index + 1) * batch_size]\n            image_batch = (image_batch - 127.5) / 127.5\n\n            # Generate fake images\n            fake_images, _ = stage1_gen.predict([embedding_batch, z_noise], verbose=3)\n\n            # Generate compressed embeddings\n            compressed_embedding = embedding_compressor_model.predict_on_batch(embedding_batch)\n            compressed_embedding = np.reshape(compressed_embedding, (-1, 1, 1, condition_dim))\n            compressed_embedding = np.tile(compressed_embedding, (1, 4, 4, 1))\n\n            dis_loss_real = stage1_dis.train_on_batch([image_batch, compressed_embedding],\n                                                      np.reshape(real_labels, (batch_size, 1)))\n            dis_loss_fake = stage1_dis.train_on_batch([fake_images, compressed_embedding],\n                                                      np.reshape(fake_labels, (batch_size, 1)))\n            dis_loss_wrong = stage1_dis.train_on_batch([image_batch[:(batch_size - 1)], compressed_embedding[1:]],\n                                                       np.reshape(fake_labels[1:], (batch_size-1, 1)))\n\n            d_loss = 0.5 * np.add(dis_loss_real, 0.5 * np.add(dis_loss_wrong, dis_loss_fake))\n\n            print(\"d_loss_real:{}\".format(dis_loss_real))\n            print(\"d_loss_fake:{}\".format(dis_loss_fake))\n            print(\"d_loss_wrong:{}\".format(dis_loss_wrong))\n            print(\"d_loss:{}\".format(d_loss))\n\n            \"\"\"\n            Train the generator network \n            \"\"\"\n            g_loss = adversarial_model.train_on_batch([embedding_batch, z_noise, compressed_embedding],[K.ones((batch_size, 1)) * 0.9, K.ones((batch_size, 256)) * 0.9])\n            print(\"g_loss:{}\".format(g_loss))\n\n            dis_losses.append(d_loss)\n            gen_losses.append(g_loss)\n\n        \"\"\"\n        Save losses to Tensorboard after each epoch\n        \"\"\"\n        write_log(tensorboard, 'discriminator_loss', np.mean(dis_losses), epoch)\n        write_log(tensorboard, 'generator_loss', np.mean(gen_losses[0]), epoch)\n        \n        # Generate and save images after every 2nd epoch\n        if epoch % 2 == 0:\n            # z_noise2 = np.random.uniform(-1, 1, size=(batch_size, z_dim))\n            z_noise2 = np.random.normal(0, 1, size=(batch_size, z_dim))\n            embedding_batch = embeddings_test[0:batch_size]\n            fake_images, _ = stage1_gen.predict_on_batch([embedding_batch, z_noise2])\n\n            # Save images\n            for i, img in enumerate(fake_images[:10]):\n                save_rgb_img(img, \"/tmp/model/results/gen_{}_{}.png\".format(epoch, i))\n # Save models\nstage1_gen.save_weights(\"stage1_gen.h5\")\nstage1_dis.save_weights(\"stage1_dis.h5\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"stage 2 train"},{"metadata":{"trusted":true},"cell_type":"code","source":"data_dir = \"../input/data birds/data birds/embed\"\ntrain_dir = data_dir + \"/train\"\ntest_dir = data_dir + \"/test\"\nhr_image_size = (256, 256)\nlr_image_size = (64, 64)\nbatch_size = 64\nz_dim = 100\nstage1_generator_lr = 0.0002\nstage1_discriminator_lr = 0.0002\nstage1_lr_decay_step = 600\nepochs = 100\ncondition_dim = 128\nembeddings_file_path_train = train_dir + \"/char-CNN-RNN-embeddings.pickle\"\nembeddings_file_path_test = test_dir + \"/char-CNN-RNN-embeddings.pickle\"\nfilenames_file_path_train = train_dir + \"/filenames.pickle\"\nfilenames_file_path_test = test_dir + \"/filenames.pickle\"\nclass_info_file_path_train = train_dir + \"/class_info.pickle\"\nclass_info_file_path_test = test_dir + \"/class_info.pickle\"\ncub_dataset_dir = \"../input/data birds/data birds/data\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Define optimizers\ndis_optimizer = Adam(lr=stage1_discriminator_lr, beta_1=0.5, beta_2=0.999)\ngen_optimizer = Adam(lr=stage1_generator_lr, beta_1=0.5, beta_2=0.999)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\"Load datasets\"\nX_hr_train, y_hr_train, embeddings_train = load_dataset(filenames_file_path=filenames_file_path_train,class_info_file_path=class_info_file_path_train,cub_dataset_dir=cub_dataset_dir,embeddings_file_path=embeddings_file_path_train,image_size=(256, 256))\n\nX_hr_test, y_hr_test, embeddings_test = load_dataset(filenames_file_path=filenames_file_path_test,class_info_file_path=class_info_file_path_test,cub_dataset_dir=cub_dataset_dir,embeddings_file_path=embeddings_file_path_test,image_size=(256, 256))\n\nX_lr_train, y_lr_train, _ = load_dataset(filenames_file_path=filenames_file_path_train,class_info_file_path=class_info_file_path_train,cub_dataset_dir=cub_dataset_dir,embeddings_file_path=embeddings_file_path_train,image_size=(64, 64))\n\nX_lr_test, y_lr_test, _ = load_dataset(filenames_file_path=filenames_file_path_test,class_info_file_path=class_info_file_path_test,cub_dataset_dir=cub_dataset_dir,embeddings_file_path=embeddings_file_path_test,image_size=(64, 64))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\ndef joint_block(inputs):\n    c = inputs[0]\n    x = inputs[1]\n\n    c = K.expand_dims(c, axis=1)\n    c = K.expand_dims(c, axis=1)\n    c = K.tile(c, [1, 16, 16, 1])\n    return K.concatenate([c, x], axis=3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def residual_block(input):\n    \"\"\"\n    Residual block in the generator network\n    \"\"\"\n    x = Conv2D(128 * 4, kernel_size=(3, 3), padding='same', strides=1)(input)\n    x = BatchNormalization()(x)\n    x = ReLU()(x)\n\n    x = Conv2D(128 * 4, kernel_size=(3, 3), strides=1, padding='same')(x)\n    x = BatchNormalization()(x)\n\n    x = add([x, input])\n    x = ReLU()(x)\n\n    return x","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def build_ca_model():\n    \"\"\"\n    Get conditioning augmentation model.\n    Takes an embedding of shape (1024,) and returns a tensor of shape (256,)\n    \"\"\"\n    input_layer = Input(shape=(1024,))\n    x = Dense(256)(input_layer)\n    x = LeakyReLU(alpha=0.2)(x)\n    model = Model(inputs=[input_layer], outputs=[x])\n    return model\n\n\ndef build_embedding_compressor_model():\n    \"\"\"\n    Build embedding compressor model\n    \"\"\"\n    input_layer = Input(shape=(1024,))\n    x = Dense(128)(input_layer)\n    x = ReLU()(x)\n    model = Model(inputs=[input_layer], outputs=[x])\n    return model\n\n\ndef generate_c(x):\n    mean = x[:, :128]\n    log_sigma = x[:, 128:]\n\n    stddev = K.exp(log_sigma)\n    epsilon = K.random_normal(shape=K.constant((mean.shape[1],), dtype='int32'))\n    c = stddev * epsilon + mean\n\n    return c\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import os\nimport pickle\nimport random\nimport time\n\nimport PIL\nimport numpy as np\nimport pandas as pd\nimport tensorflow as tf\nfrom PIL import Image\nfrom keras import Input, Model\nfrom keras import backend as K\nfrom keras.callbacks import TensorBoard\nfrom keras.layers import Dense, LeakyReLU, BatchNormalization, ReLU, Reshape, UpSampling2D, Conv2D, Activation, \\\n    concatenate, Flatten, Lambda, Concatenate, ZeroPadding2D\nfrom keras.layers import add\nfrom keras.optimizers import Adam\nfrom matplotlib import pyplot as plt","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def build_adversarial_model(gen_model2, dis_model, gen_model1):\n    \"\"\"\n    Create adversarial model\n    \"\"\"\n    embeddings_input_layer = Input(shape=(1024, ))\n    noise_input_layer = Input(shape=(100, ))\n    compressed_embedding_input_layer = Input(shape=(4, 4, 128))\n\n    gen_model1.trainable = False\n    dis_model.trainable = False\n\n    lr_images, mean_logsigma1 = gen_model1([embeddings_input_layer, noise_input_layer])\n    hr_images, mean_logsigma2 = gen_model2([embeddings_input_layer, lr_images])\n    valid = dis_model([hr_images, compressed_embedding_input_layer])\n\n    model = Model(inputs=[embeddings_input_layer, noise_input_layer, compressed_embedding_input_layer], outputs=[valid, mean_logsigma2])\n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\"\"\"\nBuild and compile models\n\"\"\"\nstage2_dis = build_stage2_discriminator()\nstage2_dis.compile(loss='binary_crossentropy', optimizer=dis_optimizer)\n\nstage1_gen = build_stage1_generator()\nstage1_gen.compile(loss=\"binary_crossentropy\", optimizer=gen_optimizer)\n\nstage1_gen.load_weights(\"stage1_gen.h5\")\n\nstage2_gen = build_stage2_generator()\nstage2_gen.compile(loss=\"binary_crossentropy\", optimizer=gen_optimizer)\n\nembedding_compressor_model = build_embedding_compressor_model()\nembedding_compressor_model.compile(loss='binary_crossentropy', optimizer='adam')\n\nadversarial_model = build_adversarial_model(stage2_gen, stage2_dis, stage1_gen)\nadversarial_model.compile(loss=['binary_crossentropy', KL_loss], loss_weights=[1.0, 2.0],\n                              optimizer=gen_optimizer, metrics=None)\n\ntensorboard = TensorBoard(log_dir=\"logs/\".format(time.time()))\ntensorboard.set_model(stage2_gen)\ntensorboard.set_model(stage2_dis)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"    # Generate an array containing real and fake values\n    # Apply label smoothing\n    real_labels = np.ones((batch_size, 1), dtype=float) * 0.9\n    fake_labels = np.zeros((batch_size, 1), dtype=float) * 0.1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"    for epoch in range(epochs):\n        print(\"========================================\")\n        print(\"Epoch is:\", epoch)\n\n        gen_losses = []\n        dis_losses = []\n\n        # Load data and train model\n        number_of_batches = int(X_hr_train.shape[0] / batch_size)\n        print(\"Number of batches:{}\".format(number_of_batches))\n        for index in range(number_of_batches):\n            print(\"Batch:{}\".format(index))\n\n            # Create a noise vector\n            z_noise = np.random.normal(0, 1, size=(batch_size, z_dim))\n            X_hr_train_batch = X_hr_train[index * batch_size:(index + 1) * batch_size]\n            embedding_batch = embeddings_train[index * batch_size:(index + 1) * batch_size]\n            X_hr_train_batch = (X_hr_train_batch - 127.5) / 127.5\n\n            # Generate fake images\n            lr_fake_images, _ = stage1_gen.predict([embedding_batch, z_noise], verbose=3)\n            hr_fake_images, _ = stage2_gen.predict([embedding_batch, lr_fake_images], verbose=3)\n\n            \"\"\"\n            4. Generate compressed embeddings\n            \"\"\"\n            compressed_embedding = embedding_compressor_model.predict_on_batch(embedding_batch)\n            compressed_embedding = np.reshape(compressed_embedding, (-1, 1, 1, condition_dim))\n            compressed_embedding = np.tile(compressed_embedding, (1, 4, 4, 1))\n\n            \"\"\"\n            5. Train the discriminator model\n            \"\"\"\n            dis_loss_real = stage2_dis.train_on_batch([X_hr_train_batch, compressed_embedding],\n                                                      np.reshape(real_labels, (batch_size, 1)))\n            dis_loss_fake = stage2_dis.train_on_batch([hr_fake_images, compressed_embedding],\n                                                      np.reshape(fake_labels, (batch_size, 1)))\n            dis_loss_wrong = stage2_dis.train_on_batch([X_hr_train_batch[:(batch_size - 1)], compressed_embedding[1:]],\n                                                       np.reshape(fake_labels[1:], (batch_size-1, 1)))\n            d_loss = 0.5 * np.add(dis_loss_real, 0.5 * np.add(dis_loss_wrong,  dis_loss_fake))\n            print(\"d_loss:{}\".format(d_loss))\n\n            \"\"\"\n            Train the adversarial model\n            \"\"\"\n            g_loss = adversarial_model.train_on_batch([embedding_batch, z_noise, compressed_embedding],\n                                                                [K.ones((batch_size, 1)) * 0.9, K.ones((batch_size, 256)) * 0.9])\n\n            print(\"g_loss:{}\".format(g_loss))\n\n            dis_losses.append(d_loss)\n            gen_losses.append(g_loss)\n\n        \"\"\"\n        Save losses to Tensorboard after each epoch\n        \"\"\"\n        write_log(tensorboard, 'discriminator_loss', np.mean(dis_losses), epoch)\n        write_log(tensorboard, 'generator_loss', np.mean(gen_losses)[0], epoch)\n\n        # Generate and save images after every 2nd epoch\n        if epoch % 2 == 0:\n            # z_noise2 = np.random.uniform(-1, 1, size=(batch_size, z_dim))\n            z_noise2 = np.random.normal(0, 1, size=(batch_size, z_dim))\n            embedding_batch = embeddings_test[0:batch_size]\n\n            lr_fake_images, _ = stage1_gen.predict([embedding_batch, z_noise2], verbose=3)\n            hr_fake_images, _ = stage2_gen.predict([embedding_batch, lr_fake_images], verbose=3)\n\n            # Save images\n            for i, img in enumerate(hr_fake_images[:10]):\n                save_rgb_img(img, \"results2/gen_{}_{}.png\".format(epoch, i))\n\n    # Saving the models\n    stage2_gen.save_weights(\"stage2_gen.h5\")\n    stage2_dis.save_weights(\"stage2_dis.h5\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import os\nimport pickle\nimport random\nimport time\n\nimport PIL\nimport numpy as np\nimport pandas as pd\nimport tensorflow as tf\nfrom PIL import Image\nfrom keras import Input, Model\nfrom keras import backend as K\nfrom keras.callbacks import TensorBoard\nfrom keras.layers import Dense, LeakyReLU, BatchNormalization, ReLU, Reshape, UpSampling2D, Conv2D, Activation, \\\n    concatenate, Flatten, Lambda, Concatenate, ZeroPadding2D\nfrom keras.layers import add\nfrom keras.optimizers import Adam\nfrom matplotlib import pyplot as plt\n\n\ndef build_ca_model():\n    \"\"\"\n    Get conditioning augmentation model.\n    Takes an embedding of shape (1024,) and returns a tensor of shape (256,)\n    \"\"\"\n    input_layer = Input(shape=(1024,))\n    x = Dense(256)(input_layer)\n    x = LeakyReLU(alpha=0.2)(x)\n    model = Model(inputs=[input_layer], outputs=[x])\n    return model\n\n\ndef build_embedding_compressor_model():\n    \"\"\"\n    Build embedding compressor model\n    \"\"\"\n    input_layer = Input(shape=(1024,))\n    x = Dense(128)(input_layer)\n    x = ReLU()(x)\n    model = Model(inputs=[input_layer], outputs=[x])\n    return model\n\n\ndef generate_c(x):\n    mean = x[:, :128]\n    log_sigma = x[:, 128:]\n\n    stddev = K.exp(log_sigma)\n    epsilon = K.random_normal(shape=K.constant((mean.shape[1],), dtype='int32'))\n    c = stddev * epsilon + mean\n\n    return c\n\n\ndef build_stage1_generator():\n    \"\"\"\n    Builds a generator model used in Stage-I\n    \"\"\"\n    input_layer = Input(shape=(1024,))\n    x = Dense(256)(input_layer)\n    mean_logsigma = LeakyReLU(alpha=0.2)(x)\n\n    c = Lambda(generate_c)(mean_logsigma)\n\n    input_layer2 = Input(shape=(100,))\n\n    gen_input = Concatenate(axis=1)([c, input_layer2])\n\n    x = Dense(128 * 8 * 4 * 4, use_bias=False)(gen_input)\n    x = ReLU()(x)\n\n    x = Reshape((4, 4, 128 * 8), input_shape=(128 * 8 * 4 * 4,))(x)\n\n    x = UpSampling2D(size=(2, 2))(x)\n    x = Conv2D(512, kernel_size=3, padding=\"same\", strides=1, use_bias=False)(x)\n    x = BatchNormalization()(x)\n    x = ReLU()(x)\n\n    x = UpSampling2D(size=(2, 2))(x)\n    x = Conv2D(256, kernel_size=3, padding=\"same\", strides=1, use_bias=False)(x)\n    x = BatchNormalization()(x)\n    x = ReLU()(x)\n\n    x = UpSampling2D(size=(2, 2))(x)\n    x = Conv2D(128, kernel_size=3, padding=\"same\", strides=1, use_bias=False)(x)\n    x = BatchNormalization()(x)\n    x = ReLU()(x)\n\n    x = UpSampling2D(size=(2, 2))(x)\n    x = Conv2D(64, kernel_size=3, padding=\"same\", strides=1, use_bias=False)(x)\n    x = BatchNormalization()(x)\n    x = ReLU()(x)\n\n    x = Conv2D(3, kernel_size=3, padding=\"same\", strides=1, use_bias=False)(x)\n    x = Activation(activation='tanh')(x)\n\n    stage1_gen = Model(inputs=[input_layer, input_layer2], outputs=[x, mean_logsigma])\n    return stage1_gen\n\n\ndef residual_block(input):\n    \"\"\"\n    Residual block in the generator network\n    \"\"\"\n    x = Conv2D(128 * 4, kernel_size=(3, 3), padding='same', strides=1)(input)\n    x = BatchNormalization()(x)\n    x = ReLU()(x)\n\n    x = Conv2D(128 * 4, kernel_size=(3, 3), strides=1, padding='same')(x)\n    x = BatchNormalization()(x)\n\n    x = add([x, input])\n    x = ReLU()(x)\n\n    return x\n\n\ndef joint_block(inputs):\n    c = inputs[0]\n    x = inputs[1]\n\n    c = K.expand_dims(c, axis=1)\n    c = K.expand_dims(c, axis=1)\n    c = K.tile(c, [1, 16, 16, 1])\n    return K.concatenate([c, x], axis=3)\n\n\ndef build_stage2_generator():\n    \"\"\"\n    Create Stage-II generator containing the CA Augmentation Network,\n    the image encoder and the generator network\n    \"\"\"\n\n    # 1. CA Augmentation Network\n    input_layer = Input(shape=(1024,))\n    input_lr_images = Input(shape=(64, 64, 3))\n\n    ca = Dense(256)(input_layer)\n    mean_logsigma = LeakyReLU(alpha=0.2)(ca)\n    c = Lambda(generate_c)(mean_logsigma)\n\n    # 2. Image Encoder\n    x = ZeroPadding2D(padding=(1, 1))(input_lr_images)\n    x = Conv2D(128, kernel_size=(3, 3), strides=1, use_bias=False)(x)\n    x = ReLU()(x)\n\n    x = ZeroPadding2D(padding=(1, 1))(x)\n    x = Conv2D(256, kernel_size=(4, 4), strides=2, use_bias=False)(x)\n    x = BatchNormalization()(x)\n    x = ReLU()(x)\n\n    x = ZeroPadding2D(padding=(1, 1))(x)\n    x = Conv2D(512, kernel_size=(4, 4), strides=2, use_bias=False)(x)\n    x = BatchNormalization()(x)\n    x = ReLU()(x)\n\n    # 3. Joint\n    c_code = Lambda(joint_block)([c, x])\n\n    x = ZeroPadding2D(padding=(1, 1))(c_code)\n    x = Conv2D(512, kernel_size=(3, 3), strides=1, use_bias=False)(x)\n    x = BatchNormalization()(x)\n    x = ReLU()(x)\n\n    # 4. Residual blocks\n    x = residual_block(x)\n    x = residual_block(x)\n    x = residual_block(x)\n    x = residual_block(x)\n\n    # 5. Upsampling blocks\n    x = UpSampling2D(size=(2, 2))(x)\n    x = Conv2D(512, kernel_size=3, padding=\"same\", strides=1, use_bias=False)(x)\n    x = BatchNormalization()(x)\n    x = ReLU()(x)\n\n    x = UpSampling2D(size=(2, 2))(x)\n    x = Conv2D(256, kernel_size=3, padding=\"same\", strides=1, use_bias=False)(x)\n    x = BatchNormalization()(x)\n    x = ReLU()(x)\n\n    x = UpSampling2D(size=(2, 2))(x)\n    x = Conv2D(128, kernel_size=3, padding=\"same\", strides=1, use_bias=False)(x)\n    x = BatchNormalization()(x)\n    x = ReLU()(x)\n\n    x = UpSampling2D(size=(2, 2))(x)\n    x = Conv2D(64, kernel_size=3, padding=\"same\", strides=1, use_bias=False)(x)\n    x = BatchNormalization()(x)\n    x = ReLU()(x)\n\n    x = Conv2D(3, kernel_size=3, padding=\"same\", strides=1, use_bias=False)(x)\n    x = Activation('tanh')(x)\n\n    model = Model(inputs=[input_layer, input_lr_images], outputs=[x, mean_logsigma])\n    return model\n\n\ndef build_stage2_discriminator():\n    \"\"\"\n    Create Stage-II discriminator network\n    \"\"\"\n    input_layer = Input(shape=(256, 256, 3))\n\n    x = Conv2D(64, (4, 4), padding='same', strides=2, input_shape=(256, 256, 3), use_bias=False)(input_layer)\n    x = LeakyReLU(alpha=0.2)(x)\n\n    x = Conv2D(128, (4, 4), padding='same', strides=2, use_bias=False)(x)\n    x = BatchNormalization()(x)\n    x = LeakyReLU(alpha=0.2)(x)\n\n    x = Conv2D(256, (4, 4), padding='same', strides=2, use_bias=False)(x)\n    x = BatchNormalization()(x)\n    x = LeakyReLU(alpha=0.2)(x)\n\n    x = Conv2D(512, (4, 4), padding='same', strides=2, use_bias=False)(x)\n    x = BatchNormalization()(x)\n    x = LeakyReLU(alpha=0.2)(x)\n\n    x = Conv2D(1024, (4, 4), padding='same', strides=2, use_bias=False)(x)\n    x = BatchNormalization()(x)\n    x = LeakyReLU(alpha=0.2)(x)\n\n    x = Conv2D(2048, (4, 4), padding='same', strides=2, use_bias=False)(x)\n    x = BatchNormalization()(x)\n    x = LeakyReLU(alpha=0.2)(x)\n\n    x = Conv2D(1024, (1, 1), padding='same', strides=1, use_bias=False)(x)\n    x = BatchNormalization()(x)\n    x = LeakyReLU(alpha=0.2)(x)\n\n    x = Conv2D(512, (1, 1), padding='same', strides=1, use_bias=False)(x)\n    x = BatchNormalization()(x)\n\n    x2 = Conv2D(128, (1, 1), padding='same', strides=1, use_bias=False)(x)\n    x2 = BatchNormalization()(x2)\n    x2 = LeakyReLU(alpha=0.2)(x2)\n\n    x2 = Conv2D(128, (3, 3), padding='same', strides=1, use_bias=False)(x2)\n    x2 = BatchNormalization()(x2)\n    x2 = LeakyReLU(alpha=0.2)(x2)\n\n    x2 = Conv2D(512, (3, 3), padding='same', strides=1, use_bias=False)(x2)\n    x2 = BatchNormalization()(x2)\n\n    added_x = add([x, x2])\n    added_x = LeakyReLU(alpha=0.2)(added_x)\n\n    input_layer2 = Input(shape=(4, 4, 128))\n\n    merged_input = concatenate([added_x, input_layer2])\n\n    x3 = Conv2D(64 * 8, kernel_size=1, padding=\"same\", strides=1)(merged_input)\n    x3 = BatchNormalization()(x3)\n    x3 = LeakyReLU(alpha=0.2)(x3)\n    x3 = Flatten()(x3)\n    x3 = Dense(1)(x3)\n    x3 = Activation('sigmoid')(x3)\n\n    stage2_dis = Model(inputs=[input_layer, input_layer2], outputs=[x3])\n    return stage2_dis\n\n\ndef build_adversarial_model(gen_model2, dis_model, gen_model1):\n    \"\"\"\n    Create adversarial model\n    \"\"\"\n    embeddings_input_layer = Input(shape=(1024, ))\n    noise_input_layer = Input(shape=(100, ))\n    compressed_embedding_input_layer = Input(shape=(4, 4, 128))\n\n    gen_model1.trainable = False\n    dis_model.trainable = False\n\n    lr_images, mean_logsigma1 = gen_model1([embeddings_input_layer, noise_input_layer])\n    hr_images, mean_logsigma2 = gen_model2([embeddings_input_layer, lr_images])\n    valid = dis_model([hr_images, compressed_embedding_input_layer])\n\n    model = Model(inputs=[embeddings_input_layer, noise_input_layer, compressed_embedding_input_layer], outputs=[valid, mean_logsigma2])\n    return model\n\n\n\"\"\"\nDataset loading related methods\n\"\"\"\n\n\ndef load_class_ids(class_info_file_path):\n    \"\"\"\n    Load class ids from class_info.pickle file\n    \"\"\"\n    with open(class_info_file_path, 'rb') as f:\n        class_ids = pickle.load(f, encoding='latin1')\n        return class_ids\n\n\ndef load_embeddings(embeddings_file_path):\n    \"\"\"\n    Function to load embeddings\n    \"\"\"\n    with open(embeddings_file_path, 'rb') as f:\n        embeddings = pickle.load(f, encoding='latin1')\n        embeddings = np.array(embeddings)\n        print('embeddings: ', embeddings.shape)\n    return embeddings\n\n\ndef load_filenames(filenames_file_path):\n    \"\"\"\n    Load filenames.pickle file and return a list of all file names\n    \"\"\"\n    with open(filenames_file_path, 'rb') as f:\n        filenames = pickle.load(f, encoding='latin1')\n    return filenames\n\n\ndef load_bounding_boxes(dataset_dir):\n    \"\"\"\n    Load bounding boxes and return a dictionary of file names and corresponding bounding boxes\n    \"\"\"\n    # Paths\n    bounding_boxes_path = os.path.join(dataset_dir, 'bounding_boxes.txt')\n    file_paths_path = os.path.join(dataset_dir, 'images.txt')\n\n    # Read bounding_boxes.txt and images.txt file\n    df_bounding_boxes = pd.read_csv(bounding_boxes_path,\n                                    delim_whitespace=True, header=None).astype(int)\n    df_file_names = pd.read_csv(file_paths_path, delim_whitespace=True, header=None)\n\n    # Create a list of file names\n    file_names = df_file_names[1].tolist()\n\n    # Create a dictionary of file_names and bounding boxes\n    filename_boundingbox_dict = {img_file[:-4]: [] for img_file in file_names[:2]}\n\n    # Assign a bounding box to the corresponding image\n    for i in range(0, len(file_names)):\n        # Get the bounding box\n        bounding_box = df_bounding_boxes.iloc[i][1:].tolist()\n        key = file_names[i][:-4]\n        filename_boundingbox_dict[key] = bounding_box\n\n    return filename_boundingbox_dict\n\n\ndef get_img(img_path, bbox, image_size):\n    \"\"\"\n    Load and resize images\n    \"\"\"\n    img = Image.open(img_path).convert('RGB')\n    width, height = img.size\n    if bbox is not None:\n        R = int(np.maximum(bbox[2], bbox[3]) * 0.75)\n        center_x = int((2 * bbox[0] + bbox[2]) / 2)\n        center_y = int((2 * bbox[1] + bbox[3]) / 2)\n        y1 = np.maximum(0, center_y - R)\n        y2 = np.minimum(height, center_y + R)\n        x1 = np.maximum(0, center_x - R)\n        x2 = np.minimum(width, center_x + R)\n        img = img.crop([x1, y1, x2, y2])\n    img = img.resize(image_size, PIL.Image.BILINEAR)\n    return img\n\n\ndef load_dataset(filenames_file_path, class_info_file_path, cub_dataset_dir, embeddings_file_path, image_size):\n    filenames = load_filenames(filenames_file_path)\n    class_ids = load_class_ids(class_info_file_path)\n    bounding_boxes = load_bounding_boxes(cub_dataset_dir)\n    all_embeddings = load_embeddings(embeddings_file_path)\n\n    X, y, embeddings = [], [], []\n\n    print(\"All embeddings shape:\", all_embeddings.shape)\n\n    for index, filename in enumerate(filenames):\n        bounding_box = bounding_boxes[filename]\n\n        try:\n            # Load images\n            img_name = '{}/images/{}.jpg'.format(cub_dataset_dir, filename)\n            img = get_img(img_name, bounding_box, image_size)\n\n            all_embeddings1 = all_embeddings[index, :, :]\n\n            embedding_ix = random.randint(0, all_embeddings1.shape[0] - 1)\n            embedding = all_embeddings1[embedding_ix, :]\n\n            X.append(np.array(img))\n            y.append(class_ids[index])\n            embeddings.append(embedding)\n        except Exception as e:\n            print(e)\n\n    X = np.array(X)\n    y = np.array(y)\n    embeddings = np.array(embeddings)\n\n    return X, y, embeddings\n\n\n\"\"\"\nLoss functions\n\"\"\"\n\n\ndef KL_loss(y_true, y_pred):\n    mean = y_pred[:, :128]\n    logsigma = y_pred[:, :128]\n    loss = -logsigma + .5 * (-1 + K.exp(2. * logsigma) + K.square(mean))\n    loss = K.mean(loss)\n    return loss\n\n\ndef custom_generator_loss(y_true, y_pred):\n    # Calculate binary cross entropy loss\n    return K.binary_crossentropy(y_true, y_pred)\n\n\ndef write_log(callback, name, loss, batch_no):\n    \"\"\"\n    Write training summary to TensorBoard\n    \"\"\"\n    summary = tf.Summary()\n    summary_value = summary.value.add()\n    summary_value.simple_value = loss\n    summary_value.tag = name\n    callback.writer.add_summary(summary, batch_no)\n    callback.writer.flush()\n\n\ndef save_rgb_img(img, path):\n    \"\"\"\n    Save an rgb image\n    \"\"\"\n    fig = plt.figure()\n    ax = fig.add_subplot(1, 1, 1)\n    ax.imshow(img)\n    ax.axis(\"off\")\n    ax.set_title(\"Image\")\n\n    plt.savefig(path)\n    plt.close()\n\n\nif __name__ == '__main__':\n    data_dir = \"../input/data birds/data birds/embed\"\n    train_dir = data_dir + \"/train\"\n    test_dir = data_dir + \"/test\"\n    hr_image_size = (256, 256)\n    lr_image_size = (64, 64)\n    batch_size = 64\n    z_dim = 100\n    stage1_generator_lr = 0.0002\n    stage1_discriminator_lr = 0.0002\n    stage1_lr_decay_step = 600\n    epochs = 1000\n    condition_dim = 128\n\n    embeddings_file_path_train = train_dir + \"/char-CNN-RNN-embeddings.pickle\"\n    embeddings_file_path_test = test_dir + \"/char-CNN-RNN-embeddings.pickle\"\n    filenames_file_path_train = train_dir + \"/filenames.pickle\"\n    filenames_file_path_test = test_dir + \"/filenames.pickle\"\n    class_info_file_path_train = train_dir + \"/class_info.pickle\"\n    class_info_file_path_test = test_dir + \"/class_info.pickle\"\n    cub_dataset_dir = \"../input/data birds/data birds/data\"\n\n    # Define optimizers\n    dis_optimizer = Adam(lr=stage1_discriminator_lr, beta_1=0.5, beta_2=0.999)\n    gen_optimizer = Adam(lr=stage1_generator_lr, beta_1=0.5, beta_2=0.999)\n\n    \"\"\"\n    Load datasets\n    \"\"\"\n    X_hr_train, y_hr_train, embeddings_train = load_dataset(filenames_file_path=filenames_file_path_train,\n                                                            class_info_file_path=class_info_file_path_train,\n                                                            cub_dataset_dir=cub_dataset_dir,\n                                                            embeddings_file_path=embeddings_file_path_train,\n                                                            image_size=(256, 256))\n\n    X_hr_test, y_hr_test, embeddings_test = load_dataset(filenames_file_path=filenames_file_path_test,\n                                                         class_info_file_path=class_info_file_path_test,\n                                                         cub_dataset_dir=cub_dataset_dir,\n                                                         embeddings_file_path=embeddings_file_path_test,\n                                                         image_size=(256, 256))\n\n    X_lr_train, y_lr_train, _ = load_dataset(filenames_file_path=filenames_file_path_train,\n                                             class_info_file_path=class_info_file_path_train,\n                                             cub_dataset_dir=cub_dataset_dir,\n                                             embeddings_file_path=embeddings_file_path_train,\n                                             image_size=(64, 64))\n\n    X_lr_test, y_lr_test, _ = load_dataset(filenames_file_path=filenames_file_path_test,\n                                           class_info_file_path=class_info_file_path_test,\n                                           cub_dataset_dir=cub_dataset_dir,\n                                           embeddings_file_path=embeddings_file_path_test,\n                                           image_size=(64, 64))\n\n    \"\"\"\n    Build and compile models\n    \"\"\"\n    stage2_dis = build_stage2_discriminator()\n    stage2_dis.compile(loss='binary_crossentropy', optimizer=dis_optimizer)\n\n    stage1_gen = build_stage1_generator()\n    stage1_gen.compile(loss=\"binary_crossentropy\", optimizer=gen_optimizer)\n\n    stage1_gen.load_weights(\"stage1_gen.h5\")\n\n    stage2_gen = build_stage2_generator()\n    stage2_gen.compile(loss=\"binary_crossentropy\", optimizer=gen_optimizer)\n\n    embedding_compressor_model = build_embedding_compressor_model()\n    embedding_compressor_model.compile(loss='binary_crossentropy', optimizer='adam')\n\n    adversarial_model = build_adversarial_model(stage2_gen, stage2_dis, stage1_gen)\n    adversarial_model.compile(loss=['binary_crossentropy', KL_loss], loss_weights=[1.0, 2.0],\n                              optimizer=gen_optimizer, metrics=None)\n\n    tensorboard = TensorBoard(log_dir=\"logs/\".format(time.time()))\n    tensorboard.set_model(stage2_gen)\n    tensorboard.set_model(stage2_dis)\n\n    # Generate an array containing real and fake values\n    # Apply label smoothing\n    real_labels = np.ones((batch_size, 1), dtype=float) * 0.9\n    fake_labels = np.zeros((batch_size, 1), dtype=float) * 0.1\n\n    for epoch in range(epochs):\n        print(\"========================================\")\n        print(\"Epoch is:\", epoch)\n\n        gen_losses = []\n        dis_losses = []\n\n        # Load data and train model\n        number_of_batches = int(X_hr_train.shape[0] / batch_size)\n        print(\"Number of batches:{}\".format(number_of_batches))\n        for index in range(number_of_batches):\n            print(\"Batch:{}\".format(index))\n\n            # Create a noise vector\n            z_noise = np.random.normal(0, 1, size=(batch_size, z_dim))\n            X_hr_train_batch = X_hr_train[index * batch_size:(index + 1) * batch_size]\n            embedding_batch = embeddings_train[index * batch_size:(index + 1) * batch_size]\n            X_hr_train_batch = (X_hr_train_batch - 127.5) / 127.5\n\n            # Generate fake images\n            lr_fake_images, _ = stage1_gen.predict([embedding_batch, z_noise], verbose=3)\n            hr_fake_images, _ = stage2_gen.predict([embedding_batch, lr_fake_images], verbose=3)\n\n            \"\"\"\n            4. Generate compressed embeddings\n            \"\"\"\n            compressed_embedding = embedding_compressor_model.predict_on_batch(embedding_batch)\n            compressed_embedding = np.reshape(compressed_embedding, (-1, 1, 1, condition_dim))\n            compressed_embedding = np.tile(compressed_embedding, (1, 4, 4, 1))\n\n            \"\"\"\n            5. Train the discriminator model\n            \"\"\"\n            dis_loss_real = stage2_dis.train_on_batch([X_hr_train_batch, compressed_embedding],\n                                                      np.reshape(real_labels, (batch_size, 1)))\n            dis_loss_fake = stage2_dis.train_on_batch([hr_fake_images, compressed_embedding],\n                                                      np.reshape(fake_labels, (batch_size, 1)))\n            dis_loss_wrong = stage2_dis.train_on_batch([X_hr_train_batch[:(batch_size - 1)], compressed_embedding[1:]],\n                                                       np.reshape(fake_labels[1:], (batch_size-1, 1)))\n            d_loss = 0.5 * np.add(dis_loss_real, 0.5 * np.add(dis_loss_wrong,  dis_loss_fake))\n            print(\"d_loss:{}\".format(d_loss))\n\n            \"\"\"\n            Train the adversarial model\n            \"\"\"\n            g_loss = adversarial_model.train_on_batch([embedding_batch, z_noise, compressed_embedding],\n                                                                [K.ones((batch_size, 1)) * 0.9, K.ones((batch_size, 256)) * 0.9])\n\n            print(\"g_loss:{}\".format(g_loss))\n\n            dis_losses.append(d_loss)\n            gen_losses.append(g_loss)\n\n        \"\"\"\n        Save losses to Tensorboard after each epoch\n        \"\"\"\n        write_log(tensorboard, 'discriminator_loss', np.mean(dis_losses), epoch)\n        write_log(tensorboard, 'generator_loss', np.mean(gen_losses)[0], epoch)\n\n        # Generate and save images after every 2nd epoch\n        if epoch % 2 == 0:\n            # z_noise2 = np.random.uniform(-1, 1, size=(batch_size, z_dim))\n            z_noise2 = np.random.normal(0, 1, size=(batch_size, z_dim))\n            embedding_batch = embeddings_test[0:batch_size]\n\n            lr_fake_images, _ = stage1_gen.predict([embedding_batch, z_noise2], verbose=3)\n            hr_fake_images, _ = stage2_gen.predict([embedding_batch, lr_fake_images], verbose=3)\n\n            # Save images\n            for i, img in enumerate(hr_fake_images[:10]):\n                save_rgb_img(img, \"results2/gen_{}_{}.png\".format(epoch, i))\n\n    # Saving the models\n    stage2_gen.save_weights(\"stage2_gen.h5\")\n    stage2_dis.save_weights(\"stage2_dis.h5\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}